{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なライブラリをインポート\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "# 自作モジュールをインポート\n",
    "from horgues3.dataset import HorguesDataset\n",
    "from horgues3.models import HorguesModel\n",
    "from horgues3.losses import HorguesLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ログ設定\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# デバイス設定\n",
    "device = torch.device('cuda:1')\n",
    "logger.info(f\"使用デバイス: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習パラメータ設定\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS = 100\n",
    "PATIENCE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習期間・検証期間設定\n",
    "TRAIN_START_DATE = '20180101'\n",
    "TRAIN_END_DATE = '20211231'\n",
    "VAL_START_DATE = '20220101'\n",
    "VAL_END_DATE = '20221231'\n",
    "\n",
    "logger.info(f\"学習期間: {TRAIN_START_DATE} - {TRAIN_END_DATE}\")\n",
    "logger.info(f\"検証期間: {VAL_START_DATE} - {VAL_END_DATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの作成\n",
    "logger.info(\"学習データセットを作成中...\")\n",
    "train_dataset = HorguesDataset(\n",
    "    start_date=TRAIN_START_DATE,\n",
    "    end_date=TRAIN_END_DATE,\n",
    "    cache_dir='cache/train',\n",
    "    use_cache=True\n",
    ")\n",
    "\n",
    "logger.info(\"検証データセットを作成中...\")\n",
    "val_dataset = HorguesDataset(\n",
    "    start_date=VAL_START_DATE,\n",
    "    end_date=VAL_END_DATE,\n",
    "    preprocessing_params=train_dataset.get_preprocessing_params(),\n",
    "    cache_dir='cache/val',\n",
    "    use_cache=True\n",
    ")\n",
    "\n",
    "logger.info(f\"学習データサイズ: {len(train_dataset)}\")\n",
    "logger.info(f\"検証データサイズ: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダーの作成\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル設定の取得\n",
    "model_config = train_dataset.get_model_config()\n",
    "logger.info(f\"数値特徴量数: {len(model_config['numerical_features'])}\")\n",
    "logger.info(f\"カテゴリ特徴量数: {len(model_config['categorical_features'])}\")\n",
    "logger.info(f\"時系列データ: {model_config['sequence_names']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの作成\n",
    "model = HorguesModel(\n",
    "    sequence_names=model_config['sequence_names'],\n",
    "    feature_aliases=model_config['feature_aliases'],\n",
    "    numerical_features=model_config['numerical_features'],\n",
    "    categorical_features=model_config['categorical_features'],\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータ数の確認\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "logger.info(f\"総パラメータ数: {total_params:,}\")\n",
    "logger.info(f\"学習可能パラメータ数: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失関数の設定\n",
    "criterion = HorguesLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# オプティマイザーの設定\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=1e-5,\n",
    "    betas=(0.9, 0.95)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# スケジューラーの設定\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer,\n",
    "    T_0=10,\n",
    "    T_mult=2,\n",
    "    eta_min=LEARNING_RATE * 0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習履歴を保存するリスト\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "learning_rates = []\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習ループ\n",
    "logger.info(\"学習を開始します...\")\n",
    "\n",
    "# 履歴を保存するためのリスト（既存のものに追加）\n",
    "val_metrics_history = {\n",
    "    'accuracy': {'top1': [], 'top2': [], 'top3': []},\n",
    "    'precision': {'top1': [], 'top2': [], 'top3': []},\n",
    "    'recall': {'top1': [], 'top2': [], 'top3': []},\n",
    "    'f1': {'top1': [], 'top2': [], 'top3': []},\n",
    "    'auroc': {'top1': [], 'top2': [], 'top3': []},\n",
    "    'average_precision': {'top1': [], 'top2': [], 'top3': []}\n",
    "}\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # 学習フェーズ\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_batches = 0\n",
    "\n",
    "    train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS} [Train]')\n",
    "    for batch in train_pbar:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # データをデバイスに移動\n",
    "        x_num = {k: v.to(device) for k, v in batch['x_num'].items()}\n",
    "        x_cat = {k: v.to(device) for k, v in batch['x_cat'].items()}\n",
    "        sequence_data = {}\n",
    "        for seq_name, seq_data in batch['sequence_data'].items():\n",
    "            sequence_data[seq_name] = {\n",
    "                'x_num': {k: v.to(device) for k, v in seq_data['x_num'].items()},\n",
    "                'x_cat': {k: v.to(device) for k, v in seq_data['x_cat'].items()},\n",
    "                'mask': seq_data['mask'].to(device)\n",
    "            }\n",
    "        mask = batch['mask'].to(device)\n",
    "        target = batch['target'].to(device)\n",
    "\n",
    "        # 前向き伝播\n",
    "        scores = model(x_num, x_cat, sequence_data, mask)\n",
    "        loss = criterion(scores, target)\n",
    "\n",
    "        # 後向き伝播\n",
    "        loss.backward()\n",
    "\n",
    "        # 勾配クリッピング\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_batches += 1\n",
    "\n",
    "        train_pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "\n",
    "    avg_train_loss = train_loss / train_batches if train_batches > 0 else 0\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # 検証フェーズ\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_batches = 0\n",
    "    \n",
    "    # 予測と正解を蓄積するリスト\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    all_scores = []  # 確率値も蓄積\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS} [Val]')\n",
    "        for batch in val_pbar:\n",
    "            # データをデバイスに移動\n",
    "            x_num = {k: v.to(device) for k, v in batch['x_num'].items()}\n",
    "            x_cat = {k: v.to(device) for k, v in batch['x_cat'].items()}\n",
    "            sequence_data = {}\n",
    "            for seq_name, seq_data in batch['sequence_data'].items():\n",
    "                sequence_data[seq_name] = {\n",
    "                    'x_num': {k: v.to(device) for k, v in seq_data['x_num'].items()},\n",
    "                    'x_cat': {k: v.to(device) for k, v in seq_data['x_cat'].items()},\n",
    "                    'mask': seq_data['mask'].to(device)\n",
    "                }\n",
    "            mask = batch['mask'].to(device)\n",
    "            target = batch['target'].to(device)\n",
    "\n",
    "            scores = model(x_num, x_cat, sequence_data, mask)\n",
    "            loss = criterion(scores, target)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_batches += 1\n",
    "            \n",
    "            # 予測値を0/1に変換（シグモイド関数を適用して閾値0.5で二値化）\n",
    "            scores_sigmoid = torch.sigmoid(scores)\n",
    "            preds = scores_sigmoid > 0.5\n",
    "            \n",
    "            # バッチの予測、正解、スコアを蓄積\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_targets.append(target.cpu())\n",
    "            all_scores.append(scores_sigmoid.cpu())  # 確率値を蓄積\n",
    "\n",
    "            val_pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "\n",
    "    avg_val_loss = val_loss / val_batches if val_batches > 0 else float('inf')\n",
    "    val_losses.append(avg_val_loss)\n",
    "    \n",
    "    # 全体の予測と正解、スコアを結合\n",
    "    all_preds = torch.cat(all_preds, dim=0)  # [total_samples, 3]\n",
    "    all_targets = torch.cat(all_targets, dim=0)  # [total_samples, 3]\n",
    "    all_scores = torch.cat(all_scores, dim=0)  # [total_samples, 3]\n",
    "    \n",
    "    # 各順位（1着以内、2着以内、3着以内）について指標を計算\n",
    "    metrics = {'accuracy': {}, 'precision': {}, 'recall': {}, 'f1': {}, 'auroc': {}, 'average_precision': {}}\n",
    "    \n",
    "    for i, position in enumerate(['top1', 'top2', 'top3']):\n",
    "        # NaNでないサンプルのマスクを作成\n",
    "        valid_mask = ~torch.isnan(all_targets[:, i])\n",
    "        \n",
    "        # 有効なサンプルのみを抽出\n",
    "        valid_preds = all_preds[valid_mask, i]\n",
    "        valid_targets = all_targets[valid_mask, i]\n",
    "        valid_scores = all_scores[valid_mask, i]\n",
    "        \n",
    "        if len(valid_preds) > 0:\n",
    "            # 各指標を計算\n",
    "            tp = ((valid_preds == 1) & (valid_targets == 1)).sum().float()\n",
    "            tn = ((valid_preds == 0) & (valid_targets == 0)).sum().float()\n",
    "            fp = ((valid_preds == 1) & (valid_targets == 0)).sum().float()\n",
    "            fn = ((valid_preds == 0) & (valid_targets == 1)).sum().float()\n",
    "            \n",
    "            # Accuracy\n",
    "            accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0\n",
    "            metrics['accuracy'][position] = accuracy.item()\n",
    "            \n",
    "            # Precision\n",
    "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            metrics['precision'][position] = precision.item()\n",
    "            \n",
    "            # Recall\n",
    "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            metrics['recall'][position] = recall.item()\n",
    "            \n",
    "            # F1 Score\n",
    "            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            metrics['f1'][position] = f1.item()\n",
    "            \n",
    "            # AUROC, Average Precision (正例が存在する場合のみ計算)\n",
    "            if valid_targets.sum() > 0 and valid_targets.sum() < len(valid_targets):\n",
    "                try:\n",
    "                    auroc = roc_auc_score(valid_targets.numpy(), valid_scores.numpy())\n",
    "                    metrics['auroc'][position] = auroc\n",
    "                    \n",
    "                    average_precision = average_precision_score(valid_targets.numpy(), valid_scores.numpy())\n",
    "                    metrics['average_precision'][position] = average_precision\n",
    "                except:\n",
    "                    logger.warning(f\"{position}の AUROC / Average Precision 計算でエラー: {e}\")\n",
    "                    logger.warning(f\"  正例数: {positive_count}, 負例数: {negative_count}\")\n",
    "                    logger.warning(f\"  スコア範囲: [{y_scores.min():.3f}, {y_scores.max():.3f}]\")\n",
    "                    metrics['auroc'][position] = 0\n",
    "                    metrics['average_precision'][position] = 0\n",
    "            else:\n",
    "                metrics['auroc'][position] = 0\n",
    "                metrics['average_precision'][position] = 0\n",
    "        else:\n",
    "            # 有効なサンプルがない場合\n",
    "            metrics['accuracy'][position] = 0\n",
    "            metrics['precision'][position] = 0\n",
    "            metrics['recall'][position] = 0\n",
    "            metrics['f1'][position] = 0\n",
    "            metrics['auroc'][position] = 0\n",
    "            metrics['average_precision'][position] = 0\n",
    "    \n",
    "    # 履歴に追加\n",
    "    for metric_name in ['accuracy', 'precision', 'recall', 'f1', 'auroc', 'average_precision']:\n",
    "        for position in ['top1', 'top2', 'top3']:\n",
    "            val_metrics_history[metric_name][position].append(metrics[metric_name][position])\n",
    "\n",
    "    # 現在の学習率を記録\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    learning_rates.append(current_lr)\n",
    "\n",
    "    # スケジューラの更新\n",
    "    scheduler.step()\n",
    "\n",
    "    # ログ出力（拡張版）\n",
    "    logger.info(f'Epoch {epoch+1}/{NUM_EPOCHS}: '\n",
    "                f'Train Loss: {avg_train_loss:.4f}, '\n",
    "                f'Val Loss: {avg_val_loss:.4f}, '\n",
    "                f'LR: {current_lr:.6f}')\n",
    "    \n",
    "    # 各順位の指標をログ出力\n",
    "    for position in ['top1', 'top2', 'top3']:\n",
    "        logger.info(f'  {position.upper()} - '\n",
    "                   f'Acc: {metrics[\"accuracy\"][position]:.4f}, '\n",
    "                   f'Prec: {metrics[\"precision\"][position]:.4f}, '\n",
    "                   f'Rec: {metrics[\"recall\"][position]:.4f}, '\n",
    "                   f'F1: {metrics[\"f1\"][position]:.4f}, '\n",
    "                   f'AUROC: {metrics[\"auroc\"][position]:.4f}, '\n",
    "                   f'AP: {metrics[\"average_precision\"][position]:.4f}')\n",
    "\n",
    "    # Best modelの保存\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "\n",
    "        # モデルの保存\n",
    "        model_save_path = Path('outputs')\n",
    "        model_save_path.mkdir(exist_ok=True)\n",
    "\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'train_loss': avg_train_loss,\n",
    "            'val_loss': avg_val_loss,\n",
    "            'val_metrics': metrics,  # 現在のエポックの指標を保存\n",
    "            'model_config': model_config,\n",
    "            'preprocessing_params': train_dataset.get_preprocessing_params(),\n",
    "            # 履歴データも保存\n",
    "            'train_losses': train_losses,\n",
    "            'val_losses': val_losses,\n",
    "            'val_metrics_history': val_metrics_history,\n",
    "            'learning_rates': learning_rates\n",
    "        }, model_save_path / 'best_model.pth')\n",
    "\n",
    "        logger.info(f'新しいベストモデルを保存しました (Val Loss: {best_val_loss:.4f})')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    # Early stopping\n",
    "    if patience_counter >= PATIENCE:\n",
    "        logger.info(f'Early stopping triggered after {epoch+1} epochs')\n",
    "        break\n",
    "\n",
    "# 学習終了時に最終的な履歴を保存\n",
    "history_save_path = Path('outputs')\n",
    "history_save_path.mkdir(exist_ok=True)\n",
    "\n",
    "torch.save({\n",
    "    'train_losses': train_losses,\n",
    "    'val_losses': val_losses,\n",
    "    'val_metrics_history': val_metrics_history,\n",
    "    'learning_rates': learning_rates,\n",
    "    'final_epoch': epoch\n",
    "}, history_save_path / 'training_history.pth')\n",
    "\n",
    "logger.info(\"学習が終了しました\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習曲線の可視化\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss', color='blue')\n",
    "plt.plot(val_losses, label='Validation Loss', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(learning_rates, label='Learning Rate', color='green')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('Learning Rate Schedule')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/training_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# オプション: 学習曲線をプロットする関数の例\n",
    "def plot_training_history(history_path='outputs/training_history.pth'):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    history = torch.load(history_path)\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 0].plot(history['train_losses'], label='Train Loss')\n",
    "    axes[0, 0].plot(history['val_losses'], label='Val Loss')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].set_title('Training and Validation Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0, 1].plot(history['val_metrics_history']['accuracy']['top1'], label='Top 1')\n",
    "    axes[0, 1].plot(history['val_metrics_history']['accuracy']['top2'], label='Top 2')\n",
    "    axes[0, 1].plot(history['val_metrics_history']['accuracy']['top3'], label='Top 3')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].set_title('Validation Accuracy')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # Precision\n",
    "    axes[0, 2].plot(history['val_metrics_history']['precision']['top1'], label='Top 1')\n",
    "    axes[0, 2].plot(history['val_metrics_history']['precision']['top2'], label='Top 2')\n",
    "    axes[0, 2].plot(history['val_metrics_history']['precision']['top3'], label='Top 3')\n",
    "    axes[0, 2].set_xlabel('Epoch')\n",
    "    axes[0, 2].set_ylabel('Precision')\n",
    "    axes[0, 2].set_title('Validation Precision')\n",
    "    axes[0, 2].legend()\n",
    "    axes[0, 2].grid(True)\n",
    "    \n",
    "    # Recall\n",
    "    axes[1, 0].plot(history['val_metrics_history']['recall']['top1'], label='Top 1')\n",
    "    axes[1, 0].plot(history['val_metrics_history']['recall']['top2'], label='Top 2')\n",
    "    axes[1, 0].plot(history['val_metrics_history']['recall']['top3'], label='Top 3')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Recall')\n",
    "    axes[1, 0].set_title('Validation Recall')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True)\n",
    "    \n",
    "    # F1 Score\n",
    "    axes[1, 1].plot(history['val_metrics_history']['f1']['top1'], label='Top 1')\n",
    "    axes[1, 1].plot(history['val_metrics_history']['f1']['top2'], label='Top 2')\n",
    "    axes[1, 1].plot(history['val_metrics_history']['f1']['top3'], label='Top 3')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('F1 Score')\n",
    "    axes[1, 1].set_title('Validation F1 Score')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True)\n",
    "    \n",
    "    # AUROC\n",
    "    axes[1, 2].plot(history['val_metrics_history']['auroc']['top1'], label='Top 1')\n",
    "    axes[1, 2].plot(history['val_metrics_history']['auroc']['top2'], label='Top 2')\n",
    "    axes[1, 2].plot(history['val_metrics_history']['auroc']['top3'], label='Top 3')\n",
    "    axes[1, 2].set_xlabel('Epoch')\n",
    "    axes[1, 2].set_ylabel('AUROC')\n",
    "    axes[1, 2].set_title('Validation AUROC')\n",
    "    axes[1, 2].legend()\n",
    "    axes[1, 2].grid(True)\n",
    "    \n",
    "    # Average Precision\n",
    "    axes[2, 0].plot(history['val_metrics_history']['average_precision']['top1'], label='Top 1')\n",
    "    axes[2, 0].plot(history['val_metrics_history']['average_precision']['top2'], label='Top 2')\n",
    "    axes[2, 0].plot(history['val_metrics_history']['average_precision']['top3'], label='Top 3')\n",
    "    axes[2, 0].set_xlabel('Epoch')\n",
    "    axes[2, 0].set_ylabel('Average Precision')\n",
    "    axes[2, 0].set_title('Validation Average Precision')\n",
    "    axes[2, 0].legend()\n",
    "    axes[2, 0].grid(True)\n",
    "    \n",
    "    # Learning Rate\n",
    "    axes[2, 1].plot(history['learning_rates'])\n",
    "    axes[2, 1].set_xlabel('Epoch')\n",
    "    axes[2, 1].set_ylabel('Learning Rate')\n",
    "    axes[2, 1].set_title('Learning Rate Schedule')\n",
    "    axes[2, 1].grid(True)\n",
    "    \n",
    "    # 最後のサブプロットは空にする\n",
    "    axes[2, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('outputs/training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終結果の表示\n",
    "logger.info(f\"最良の検証損失: {best_val_loss:.4f}\")\n",
    "logger.info(f\"学習データ最終損失: {train_losses[-1]:.4f}\")\n",
    "logger.info(f\"検証データ最終損失: {val_losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習済みモデルのロード（確認用）\n",
    "logger.info(\"保存されたベストモデルをロードして確認...\")\n",
    "checkpoint = torch.load('outputs/best_model.pth', map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "logger.info(f\"ベストモデル (Epoch {checkpoint['epoch']+1}) をロードしました\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "horgues3",
   "language": "python",
   "name": "horgues3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
