{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import logging\n",
    "from horgues3.dataset import HorguesDataset\n",
    "from horgues3.models import HorguesModel, PlackettLuceLoss, WeightedPlackettLuceLoss, ListwiseLoss, PairwiseRankingLoss, CombinedRankingLoss, RankNetLoss\n",
    "from horgues3.betting import calculate_betting_probabilities, format_betting_results, extract_winning_tickets\n",
    "from horgues3.metrics import BettingAccuracyMetric, ExpectedValueBettingMetric, BettingCalibrationMetric, RankCorrelationMetric\n",
    "from horgues3.odds import fetch_odds_data, restructure_odds_data\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# ログ設定\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s | %(levelname)s | %(message)s',\n",
    "    datefmt='%H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epochs = 100\n",
    "batch_size = 128\n",
    "\n",
    "train_start_ymd = '20140101'\n",
    "train_end_ymd = '20231231'\n",
    "\n",
    "val_start_ymd = '20240101'\n",
    "val_end_ymd = '20241231'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logger.info(f\"Using device: {device}\")\n",
    "\n",
    "# 学習データの準備\n",
    "logger.info('Preparing train dataset...')\n",
    "train_dataset = HorguesDataset(train_start_ymd, train_end_ymd, max_horses=18)\n",
    "train_dataset.fetch().prepare().build().fit().transform()\n",
    "\n",
    "# 検証データの準備\n",
    "logger.info('Preparing val dataset')\n",
    "val_dataset = HorguesDataset(val_start_ymd, val_end_ymd, max_horses=18)\n",
    "val_dataset.fetch().prepare().build().set_params(train_dataset.get_params()).transform()\n",
    "\n",
    "logger.info(\"Dataset preparation done.\")\n",
    "logger.info(f\"Training samples: {len(train_dataset)}\")\n",
    "logger.info(f\"Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "# データローダー\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=0  # Windowsでは0に設定\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings = val_dataset.transformed_data['rankings']\n",
    "mask = val_dataset.transformed_data['mask']\n",
    "\n",
    "# 的中馬券\n",
    "winning_tickets = extract_winning_tickets(rankings, mask)\n",
    "\n",
    "# オッズ\n",
    "logging.info('Preparing odds data...')\n",
    "odds_data = fetch_odds_data(val_start_ymd, val_end_ymd)\n",
    "restructured_odds_data = restructure_odds_data(odds_data, val_dataset.transformed_data['race_id'])\n",
    "\n",
    "# メトリクス\n",
    "logging.info('Preparing metrics...')\n",
    "metric_calculators = [\n",
    "    BettingAccuracyMetric(rankings, mask, winning_tickets),\n",
    "    ExpectedValueBettingMetric(rankings, mask, winning_tickets, restructured_odds_data),\n",
    "    BettingCalibrationMetric(rankings, mask, winning_tickets),\n",
    "    RankCorrelationMetric(rankings, mask),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('Preparing model...')\n",
    "\n",
    "# モデル設定\n",
    "model = HorguesModel(train_dataset.get_params()).to(device)\n",
    "\n",
    "# 損失関数とオプティマイザ\n",
    "criterion = WeightedPlackettLuceLoss()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=total_epochs,  # エポック数に合わせて調整\n",
    "    eta_min=1e-6\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"1エポックの学習\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    grad_norms = []\n",
    "    \n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # データをデバイスに移動\n",
    "        x_num = {k: v.to(device) for k, v in batch['x_num'].items()}\n",
    "        x_cat = {k: v.to(device) for k, v in batch['x_cat'].items()}\n",
    "        rankings = batch['rankings'].to(device)\n",
    "        mask = batch['mask'].to(device)\n",
    "        \n",
    "        # 予測\n",
    "        scores = model(x_num=x_num, x_cat=x_cat, mask=mask)\n",
    "        \n",
    "        # 損失計算\n",
    "        loss = criterion(scores, rankings, mask)\n",
    "        \n",
    "        # 逆伝播\n",
    "        loss.backward()\n",
    "        \n",
    "        # 勾配ノルムを記録\n",
    "        total_grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        grad_norms.append(total_grad_norm.item())\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "    return {\n",
    "        'loss': total_loss / num_batches if num_batches > 0 else 0,\n",
    "        'grad_norm': {\n",
    "            'mean': np.mean(grad_norms),\n",
    "            'max': np.max(grad_norms),\n",
    "            'min': np.min(grad_norms),\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model, dataloader, criterion, metric_calculators, device):\n",
    "    \"\"\"1エポックの検証\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    all_scores = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Validation\"):\n",
    "            # データをデバイスに移動\n",
    "            x_num = {k: v.to(device) for k, v in batch['x_num'].items()}\n",
    "            x_cat = {k: v.to(device) for k, v in batch['x_cat'].items()}\n",
    "            rankings = batch['rankings'].to(device)\n",
    "            mask = batch['mask'].to(device)\n",
    "            \n",
    "            # 予測\n",
    "            scores = model(x_num=x_num, x_cat=x_cat, mask=mask)\n",
    "            \n",
    "            # 損失計算\n",
    "            loss = criterion(scores, rankings, mask)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "            # メトリクス計算用にスコアを保存\n",
    "            all_scores.append(scores.cpu().numpy())\n",
    "\n",
    "    all_scores = np.concatenate(all_scores, axis=0)\n",
    "    betting_probabilities = calculate_betting_probabilities(all_scores)\n",
    "\n",
    "    metrics = {}\n",
    "    for calculator in metric_calculators:\n",
    "        metrics.update(calculator(betting_probabilities))\n",
    "\n",
    "    return {\n",
    "        'loss': total_loss / num_batches if num_batches > 0 else 0,\n",
    "        **metrics\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_metrics(metrics_dict, indent=0):\n",
    "    \"\"\"\n",
    "    メトリクス辞書を整形して表示用の文字列に変換\n",
    "    \n",
    "    Args:\n",
    "        metrics_dict: メトリクス辞書\n",
    "        indent: インデント数\n",
    "    \n",
    "    Returns:\n",
    "        str: 整形された文字列\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "    indent_str = \"  \" * indent\n",
    "    \n",
    "    for key, value in metrics_dict.items():\n",
    "        if isinstance(value, dict):\n",
    "            lines.append(f\"{indent_str}{key}:\")\n",
    "            lines.append(format_metrics(value, indent + 1))\n",
    "        elif isinstance(value, (int, float)):\n",
    "            if isinstance(value, float):\n",
    "                lines.append(f\"{indent_str}{key}: {value:.4f}\")\n",
    "            else:\n",
    "                lines.append(f\"{indent_str}{key}: {value}\")\n",
    "        elif hasattr(value, 'item'):  # numpy scalar\n",
    "            lines.append(f\"{indent_str}{key}: {value.item():.4f}\")\n",
    "        else:\n",
    "            lines.append(f\"{indent_str}{key}: {value}\")\n",
    "    \n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習ループ\n",
    "logging.info(\"Initiating training...\")\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "history = []\n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "    logger.info(f\"Epoch {epoch+1}/{total_epochs}\")\n",
    "    epoch_info = {}\n",
    "    \n",
    "    # 学習\n",
    "    epoch_info['train'] = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # 検証\n",
    "    epoch_info['val'] = validate_epoch(model, val_loader, criterion, metric_calculators, device)\n",
    "    \n",
    "    # スケジューラーを更新\n",
    "    scheduler.step()\n",
    "    \n",
    "    # 整形されたメトリクスをログ出力\n",
    "    formatted_metrics = format_metrics(epoch_info)\n",
    "    logger.info(f\"=== Epoch {epoch+1}/{total_epochs} Results ===\\n{formatted_metrics}\")\n",
    "    \n",
    "    # ヒストリに記録\n",
    "    history.append(epoch_info)\n",
    "\n",
    "    # ベストモデルの保存\n",
    "    val_loss = epoch_info['val']['loss']\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'val_loss': val_loss,\n",
    "            'dataset_params': train_dataset.get_params()\n",
    "        }, 'best_model.pth')\n",
    "        logger.info(f\"New best model saved with val_loss: {val_loss:.4f}\")\n",
    "\n",
    "logger.info(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "horgues3",
   "language": "python",
   "name": "horgues3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
